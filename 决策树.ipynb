{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "novel-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "def remove(data: list, axis: int):\n",
    "    _1 = data[0:axis]\n",
    "    _2 = data[axis + 1:len(data)]\n",
    "    _1.extend(_2)\n",
    "    return _1\n",
    "\n",
    "\n",
    "def majority_value(data_set, target_attr):\n",
    "    \"\"\"\n",
    "    Majority values from data_set with target_attr.\n",
    "    \"\"\"\n",
    "    # Count labels from data set\n",
    "    labels_dict = {}\n",
    "    values_list = []\n",
    "\n",
    "    for i in [c[-1] for c in data_set]:\n",
    "        # select last node (same attribute) in data set\n",
    "        if i not in values_list:\n",
    "            # record the values that could be, like 0, 1, 2, 3 or 17\n",
    "            # (17 is ID and was deleted already. 0, 1 is colors or something else)\n",
    "            values_list.append(i)\n",
    "    # each line in data\n",
    "    for line in data_set:\n",
    "        # select each target attribute in line, in number is like 1, 2, 3. In Chinese is 青绿.\n",
    "        label = line[target_attr]\n",
    "        # if this label not in dict, create and + 1.\n",
    "        labels_dict[label] = labels_dict.get(label, 0) + 1\n",
    "\n",
    "    for i in range(len(values_list) - 1):\n",
    "        # branching according to the number of corresponding attributes\n",
    "        if labels_dict[values_list[i]] < labels_dict[values_list[i + 1]]:\n",
    "            values_list.pop(i)\n",
    "        else:\n",
    "            values_list.pop(i + 1)\n",
    "    # returns the classification result of the most likely corresponding attribute\n",
    "    return values_list[0]\n",
    "\n",
    "\n",
    "def get_values(dataset, best_attribute, attributes):\n",
    "    index = attributes.index(best_attribute)\n",
    "    tmp_values = []\n",
    "    for a in [c[index] for c in dataset]:\n",
    "        if a not in tmp_values:\n",
    "            tmp_values.append(a)\n",
    "    return tmp_values\n",
    "\n",
    "\n",
    "def get_shannon_ent(sub_data_set):\n",
    "    num_entries = len(sub_data_set)\n",
    "    labels_dict = {}\n",
    "\n",
    "    for line in sub_data_set:\n",
    "        label = line[-1]\n",
    "        labels_dict[label] = labels_dict.get(label, 0) + 1\n",
    "\n",
    "    shannon_ent = 0.0\n",
    "\n",
    "    for key in labels_dict:\n",
    "        prob = float(labels_dict[key]) / num_entries\n",
    "        shannon_ent -= prob * log(prob, 2)\n",
    "\n",
    "    return shannon_ent\n",
    "\n",
    "\n",
    "def get_examples(data_set, axis, value):\n",
    "    ret_data_set = []\n",
    "    for feat_vec in data_set:\n",
    "        if feat_vec[axis] == value:\n",
    "            reduced_feat_vec = feat_vec[:axis]\n",
    "            reduced_feat_vec.extend(feat_vec[axis + 1:])\n",
    "            ret_data_set.append(reduced_feat_vec)\n",
    "    return ret_data_set\n",
    "\n",
    "\n",
    "def choose_attribute(data_set, attributes):\n",
    "    num_features = len(data_set[0]) - 1\n",
    "    base_entropy = get_shannon_ent(data_set)\n",
    "    best_info_gain = 0.0\n",
    "    best_feature = -1\n",
    "\n",
    "    for i in range(num_features):\n",
    "        feat_list = [example[i] for example in data_set]\n",
    "        unique_vals = set(feat_list)\n",
    "        new_entropy = 0.0\n",
    "\n",
    "        for value in unique_vals:\n",
    "            sub_data_set = get_examples(data_set, i, value)\n",
    "            prob = len(sub_data_set) / float(len(data_set))\n",
    "            new_entropy += prob * get_shannon_ent(sub_data_set)\n",
    "        info_gain = base_entropy - new_entropy\n",
    "        if info_gain > best_info_gain:\n",
    "            best_info_gain = info_gain\n",
    "            best_feature = attributes[i]\n",
    "    return best_feature\n",
    "\n",
    "\n",
    "def create_decision_tree(data, attributes, target_attr, call_count, source_attributes_num):\n",
    "    call_count += 1\n",
    "    print(\"call_count:\", call_count)\n",
    "    data = data[:]\n",
    "    vals = [record[target_attr] for record in data]\n",
    "    default = majority_value(data, target_attr)\n",
    "    # If the dataset is empty or the attributes list is empty, return the\n",
    "    # default value. When checking the attributes list for emptiness, we\n",
    "    # need to subtract 1 to account for the target attribute.\n",
    "    if not data or (len(attributes)) <= 0:\n",
    "        return default\n",
    "    # If all the records in the dataset have the same classification,\n",
    "    # return that classification.\n",
    "    elif vals.count(vals[0]) == len(vals):\n",
    "        return vals[0]\n",
    "    else:\n",
    "        # Choose the next best attribute to best classify our data\n",
    "        best = choose_attribute(data, attributes)\n",
    "        # Create a new decision tree/node with the best attribute and an empty\n",
    "        # dictionary object--we'll fill that up next.\n",
    "        tree = {best: {}}\n",
    "        # Create a new decision tree/sub-node for each of the values in the\n",
    "        # best attribute field\n",
    "        test_val = get_values(data, best, attributes)\n",
    "        for i in source_attributes_num[attributes.index(best)]:\n",
    "            if i not in test_val:\n",
    "                tree[best][i] = default\n",
    "\n",
    "        for val in test_val:\n",
    "            # Create a subtree for the current value under the \"best\" field\n",
    "            subtree = create_decision_tree(get_examples(data, attributes.index(best), val),\n",
    "                                           [attr for attr in attributes if attr != best],\n",
    "                                           target_attr, call_count,\n",
    "                                           remove(source_attributes_num, attributes.index(best)))\n",
    "            # Add the new subtree to the empty dictionary object in our new\n",
    "            # tree/node we just created.\n",
    "            tree[best][val] = subtree\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reserved-record",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call_count: 1\n",
      "call_count: 2\n",
      "call_count: 3\n",
      "call_count: 3\n",
      "call_count: 4\n",
      "call_count: 4\n",
      "call_count: 5\n",
      "call_count: 5\n",
      "call_count: 3\n",
      "call_count: 2\n",
      "call_count: 3\n",
      "call_count: 3\n",
      "call_count: 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # read data\n",
    "    import csv\n",
    "\n",
    "    csv_reader = csv.reader(open(\"wm3.csv\"))\n",
    "\n",
    "    # remove the first ID line (preventing the over-fitting problem)\n",
    "    source_data = [row[1:] for row in csv_reader]\n",
    "\n",
    "    # attributes in Chinese\n",
    "    attributes_labels = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']\n",
    "\n",
    "    # get attributes in number\n",
    "    attributes_nums = []\n",
    "    for y in range(len(source_data[0]) - 1):\n",
    "        tmp = []\n",
    "        for x in range(len(source_data)):\n",
    "            if source_data[x][y] not in tmp:\n",
    "                tmp.append(source_data[x][y])\n",
    "        attributes_nums.append(tmp)\n",
    "\n",
    "    # generate predict data\n",
    "    prediction = create_decision_tree(source_data, attributes_labels, -1, 0, attributes_nums)\n",
    "\n",
    "    # store prediction result as dict string\n",
    "    with open('prediction.txt', 'w', encoding=\"utf-8\") as dict_file:\n",
    "        dict_file.write(str(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
